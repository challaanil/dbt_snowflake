import json
import boto3
import datetime
import logging
from botocore.exceptions import ClientError
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from zoneinfo import ZoneInfo

# Setting logger
LOG_FORMAT = '%(asctime)s %(levelname)s %(name)s: %(message)s'
DATE_FORMAT = '%Y-%m-%d %H:%M:%S'
logging.basicConfig(format=LOG_FORMAT, datefmt=DATE_FORMAT)
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

def get_file_size(bucket_name, file_key):
    """Retrieve the file size from S3."""
    try:
        s3_client = boto3.client('s3')
        response = s3_client.head_object(Bucket=bucket_name, Key=file_key)
        file_size = response['ContentLength'] / (1024 * 1024)  # Convert to MB
        logger.info(f"File size for {file_key}: {file_size:.2f} MB")
        return file_size
    except ClientError as e:
        logger.error(f"Error retrieving size for {file_key}: {e}")
        return None

def invoke_lambda_function(lambda_jobname, lambda_event):
    """Invoke an AWS Lambda function."""
    try:
        logger.info(f"Invoking Lambda function: {lambda_jobname}")
        lambda_client = boto3.client('lambda')
        lambda_client.invoke(
            FunctionName=lambda_jobname,
            InvocationType="Event",
            Payload=json.dumps(lambda_event)
        )
        logger.info(f"Lambda function {lambda_jobname.split(':')[-1]} invoked successfully.")
    except Exception as e:
        logger.error(f"Error invoking Lambda function {lambda_jobname}: {e}")

def invoke_glue_job(glue_jobname, glue_event):
    """Invoke an AWS Glue job."""
    try:
        logger.info(f"Invoking Glue job: {glue_jobname}")
        glue_client = boto3.client('glue')
        response = glue_client.start_job_run(
            JobName=glue_jobname,
            Arguments={"--lambda_event": json.dumps(glue_event)}
        )
        logger.info(f"Glue Job {glue_jobname} invoked successfully with JobRunID: {response['JobRunId']}")
    except Exception as e:
        logger.error(f"Error invoking Glue job {glue_jobname}: {e}")

def read_config_from_s3(bucket_name, s3_key):
    """Read configuration file from S3."""
    try:
        s3_client = boto3.client('s3')
        response = s3_client.get_object(Bucket=bucket_name, Key=s3_key)
        file_content = response['Body'].read().decode('utf-8')
        config_data = json.loads(file_content)
        logger.info(f"Configuration data loaded: {config_data}")
        return config_data
    except Exception as e:
        logger.error(f"Error reading configuration from S3: {e}")
        return {}

def process_metadata(metadata, bucket_name):
    """Process metadata entries to calculate file sizes."""
    try:
        s3_client = boto3.client('s3')
        for entry in metadata:
            s3_path = entry.get("s3_path")
            if not s3_path:
                logger.warning(f"Missing s3_path in metadata entry: {entry}")
                continue

            if s3_path.endswith("/"):
                paginator = s3_client.get_paginator('list_objects_v2')
                folder_size = 0
                for page in paginator.paginate(Bucket=bucket_name, Prefix=s3_path):
                    for obj in page.get('Contents', []):
                        file_key = obj['Key']
                        file_size = get_file_size(bucket_name, file_key)
                        if file_size:
                            folder_size += file_size
                entry["filesize"] = folder_size
            else:
                file_size = get_file_size(bucket_name, s3_path)
                entry["filesize"] = file_size

        logger.info("Metadata processing complete.")
        return metadata
    except Exception as e:
        logger.error(f"Error processing metadata: {e}")
        return metadata

def send_email_notification(email_lambda_name, email_recipients, subject, body):
    """Send an email notification using a Lambda function."""
    try:
        email_payload = {
            "email_recipients": email_recipients,
            "email_subject": subject,
            "email_body_html": body
        }
        logger.info("Sending email notification...")
        lambda_client = boto3.client('lambda')
        lambda_client.invoke(
            FunctionName=email_lambda_name,
            InvocationType="Event",
            Payload=json.dumps(email_payload)
        )
        logger.info(f"Email notification sent via {email_lambda_name}.")
    except Exception as e:
        logger.error(f"Error sending email notification: {e}")

def lambda_handler(event, context):
    """Main Lambda handler."""
    bucket_name = "tmk-cdm-landing"
    s3_key = "tmk/gf_test/config/json_config/source_configfile/file_transfer_metadata.json"
    lambda_jobname = "arn:aws:lambda:us-west-2:896172592430:function:gl-test-smb-file-transfer"
    glue_jobname = "gl-acturial-file-transfer-test_v1"
    email_lambda_name = "arn:aws:lambda:us-west-2:896172592430:function:smb-file-transfer_email_notification_test"

    try:
        logger.info("Reading configuration...")
        config_data = read_config_from_s3(bucket_name, s3_key)
        email_recipients = config_data.get("email_recipients", [])

        if not email_recipients:
            logger.warning("No email recipients specified in configuration.")

        metadata = process_metadata(config_data.get("parameter", []), bucket_name)

        timeout_threshold = context.get_remaining_time_in_millis() / 1000 - 10

        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = {
                executor.submit(process_event, event, lambda_jobname, glue_jobname): event
                for event in metadata
            }

            for future in as_completed(futures):
                try:
                    future.result()
                    if time.time() > timeout_threshold:
                        raise TimeoutError("Lambda function is nearing timeout.")
                except TimeoutError as te:
                    logger.error("Timeout error detected.")
                    send_email_notification(
                        email_lambda_name,
                        email_recipients,
                        "Lambda Timeout Alert",
                        "The Lambda function is about to timeout. Please review the logs and investigate."
                    )
                except Exception as e:
                    logger.error(f"Error processing event: {e}")

        return {
            'statusCode': 200,
            'body': json.dumps("Processing complete.")
        }

    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        send_email_notification(
            email_lambda_name,
            email_recipients,
            "Lambda Execution Error",
            f"An error occurred during Lambda execution: {str(e)}"
        )
        return {
            'statusCode': 500,
            'body': json.dumps(f"Error: {str(e)}")
        }
